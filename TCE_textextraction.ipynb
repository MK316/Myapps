{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMQ0ppaqaqo6ImdJ7a5vWzT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Myapps/blob/main/TCE_textextraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JTus8ULTIjde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Install required libraries\n",
        "%%capture\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "ljykv_V5Im2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHQQhMTRIdwP"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Step 3: Set the path to the Google Drive folder containing your images\n",
        "image_folder_path = \"/content/drive/My Drive/datafiles/TCE\"  # Change this to your Google Drive folder\n",
        "\n",
        "# Step 4: Make a list of image files (png, PNG, JPG) in the folder\n",
        "image_file_list = [f for f in os.listdir(image_folder_path) if f.endswith(('.png', '.PNG', '.JPG', '.jpg'))]\n",
        "\n",
        "# Step 5: Create an empty list to store extracted data\n",
        "extracted_data = []\n",
        "\n",
        "# Step 6: For each image file, extract text and save filename and text to the dataframe\n",
        "for image_file in image_file_list:\n",
        "    # Load the image\n",
        "    image_path = os.path.join(image_folder_path, image_file)\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Extract text from the image (English only)\n",
        "    extracted_text = pytesseract.image_to_string(img, lang='eng')\n",
        "\n",
        "    # Append filename and text to the list\n",
        "    extracted_data.append([image_file, extracted_text])\n",
        "\n",
        "# Step 7: Create a dataframe with 'Filename' and 'Text' columns\n",
        "df = pd.DataFrame(extracted_data, columns=['Filename', 'Text'])\n",
        "\n",
        "# Step 8: Display the dataframe\n",
        "df.head()\n",
        "\n",
        "# (Optional) Save the dataframe to a CSV file in your Google Drive\n",
        "df.to_csv('/content/extracted_texts.csv', encoding='utf-8', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Textdata to process"
      ],
      "metadata": {
        "id": "Q1xN8pADJI7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Step 1: Read the CSV file from your Colab folder\n",
        "df = pd.read_csv('/content/extracted_texts.csv')\n",
        "\n",
        "# Step 2: Define a function to clean broken characters, remove strings inside square brackets, angle brackets, numbers inside parentheses, and non-word strings\n",
        "def clean_text(text):\n",
        "    # Remove text inside square brackets, including the brackets themselves\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "\n",
        "    # Remove text inside angle brackets <>, including the brackets\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Remove numbers inside parentheses (), including the parentheses\n",
        "    text = re.sub(r'\\(.*?\\d+.*?\\)', '', text)\n",
        "\n",
        "    # Remove unwanted broken characters (Replace '?' and broken characters)\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Removes non-ASCII characters\n",
        "\n",
        "    # Remove non-word strings (anything that is not a letter, digit, or underscore)\n",
        "    text = re.sub(r'\\W+', ' ', text)  # Replaces non-word characters with a space\n",
        "\n",
        "    # Optionally, you can remove leading/trailing whitespaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Step 3: Apply the cleaning function to the 'Text' column and store the cleaned text in a new column 'Cleantext'\n",
        "df['Cleantext'] = df['Text'].apply(clean_text)\n",
        "\n",
        "# Step 4: Save the cleaned DataFrame as a new CSV file with utf-8 encoding\n",
        "df.to_csv('/content/CleanTCE.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# Step 5: Check the first few rows of the cleaned DataFrame\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "ERzYgCDvLs06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency list"
      ],
      "metadata": {
        "id": "tFkHaCluUd7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Step 1: Load the CSV file\n",
        "url = \"CleanTCE.csv\"  # Make sure your CSV file is in your Colab environment or replace it with the correct path\n",
        "df = pd.read_csv(url, encoding='utf-8-sig')\n",
        "\n",
        "# Step 2: Combine all the text from the 'TEXT' column into a single string\n",
        "combined_text = \" \".join(df['Cleantext'].dropna())  # Drop any NaN values if they exist, then combine\n",
        "\n",
        "# Step 3: Save the combined text as 'tceall.txt'\n",
        "with open('/content/tceall.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(combined_text)\n",
        "\n",
        "# Step 4: Clean the text and prepare it for frequency analysis\n",
        "# Convert the text to lowercase, remove punctuation and split it into words\n",
        "cleaned_text = re.sub(r'[^\\w\\s]', '', combined_text.lower())  # Remove punctuation and convert to lowercase\n",
        "words = cleaned_text.split()  # Split text into individual words\n",
        "\n",
        "# Step 5: Create a frequency list of the words\n",
        "word_freq = Counter(words)  # Use Counter to count the frequency of each word\n",
        "\n",
        "# Step 6: Convert the frequency list into a DataFrame\n",
        "freq_df = pd.DataFrame(word_freq.items(), columns=['Word', 'Frequency'])\n",
        "\n",
        "# Step 7: Sort the frequency list by the most frequent words\n",
        "freq_df = freq_df.sort_values(by='Frequency', ascending=False)\n",
        "\n",
        "# Step 8: Save the frequency list as 'TCEfreq.csv'\n",
        "freq_df.to_csv('/content/TCEfreq.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# Display the top 10 most frequent words as a quick check\n",
        "freq_df.head(10)\n"
      ],
      "metadata": {
        "id": "3kSeHqOqUftu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the existing frequency file 'TCEfreq.csv'\n",
        "df = pd.read_csv('/content/TCEfreq.csv', encoding='utf-8')\n",
        "\n",
        "# Step 2: Filter rows where the 'Word' column contains strings with more than 4 characters\n",
        "df_long_words = df[df['Word'].apply(lambda x: len(x) > 4)]\n",
        "\n",
        "# Step 3: Save the filtered DataFrame as 'TCEfreq-long.csv'\n",
        "df_long_words.to_csv('/content/TCEfreq-long.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# Step 4: Display the first few rows of the filtered DataFrame as a check\n",
        "df_long_words.head()\n"
      ],
      "metadata": {
        "id": "ZE0s6lsbVLO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_long_words['Word'])"
      ],
      "metadata": {
        "id": "JkFsxpN_VSyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display a sentence with a keyword (Incomplete)"
      ],
      "metadata": {
        "id": "KkYHx8g2e29w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "TJWlXjIUe_Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import gradio as gr\n",
        "\n",
        "# Step 1: Load the CSV file 'extracted_texts.csv'\n",
        "df = pd.read_csv('/content/extracted_texts.csv', encoding='utf-8')\n",
        "\n",
        "# Step 2: Combine all the text from the 'Text' column into a single string\n",
        "combined_text = \" \".join(df['Text'].dropna())  # Drop any NaN values, then combine the text\n",
        "\n",
        "# Step 3: Split the text into sentences while keeping punctuation intact\n",
        "sentences = re.split(r'(?<=[.!?]) +', combined_text)  # Split at end of sentences (.!?), followed by space\n",
        "\n",
        "# Step 4: Define the function to search for sentences containing a specific word\n",
        "def search_sentences(word):\n",
        "    # Find sentences containing the word (case insensitive)\n",
        "    matching_sentences = [sentence for sentence in sentences if re.search(rf'\\b{word}\\b', sentence, re.IGNORECASE)]\n",
        "\n",
        "    if matching_sentences:\n",
        "        # Return matching sentences, joining them with a double newline for readability\n",
        "        return '\\n\\n'.join(matching_sentences)\n",
        "    else:\n",
        "        # If no matches found, return this message\n",
        "        return f\"No sentences found containing the word: {word}\"\n",
        "\n",
        "# Step 5: Create the Gradio interface\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# Sentence Search Engine ðŸ”\")\n",
        "    gr.Markdown(\"Search for sentences containing a specific word from the text.\")\n",
        "\n",
        "    # Textbox for user to input the search word\n",
        "    word_input = gr.Textbox(label=\"Enter a word to search for\", placeholder=\"e.g., education\")\n",
        "\n",
        "    # Button to trigger the search\n",
        "    search_button = gr.Button(\"Search Sentences\")\n",
        "\n",
        "    # Output area for displaying the results\n",
        "    output = gr.Textbox(label=\"Sentences Containing the Word\", interactive=False)\n",
        "\n",
        "    # Connect the button to the search function\n",
        "    search_button.click(fn=search_sentences, inputs=[word_input], outputs=output)\n",
        "\n",
        "# Step 6: Launch the Gradio app\n",
        "app.launch()\n"
      ],
      "metadata": {
        "id": "b-k_fGb7e6Q8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}