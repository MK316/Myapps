{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOK89yA0vmJpFTQNS16Tlmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Myapps/blob/main/Intonation1213.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool to assist intonation analysis"
      ],
      "metadata": {
        "id": "6YtrLlNQ1cmJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-mB6lyMyFr5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ðŸ“Œ Run this code before you start\n",
        "%%capture\n",
        "!pip install pyqrcode gradio pandas gtts requests librosa matplotlib pydub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part I. Generate audio and visible pitch contour (intonation)**\n"
      ],
      "metadata": {
        "id": "vFtpgBBs_c63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown [1] Generate speech audio file: you can type a word or sentence\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "from IPython.display import Audio  # Import the Audio class for playing audio\n",
        "\n",
        "# Function to generate and save a WAV file\n",
        "def generate_and_save_wav(word, filename='output.wav'):\n",
        "    # Generate speech using gTTS\n",
        "    tts = gTTS(text=word, lang='en')\n",
        "\n",
        "    # Save as MP3 in memory\n",
        "    mp3_fp = BytesIO()\n",
        "    tts.write_to_fp(mp3_fp)\n",
        "    mp3_fp.seek(0)\n",
        "\n",
        "    # Convert MP3 to WAV\n",
        "    sound = AudioSegment.from_file(mp3_fp, format=\"mp3\")\n",
        "    sound.export(filename, format=\"wav\")\n",
        "\n",
        "    # Play the audio\n",
        "    return Audio(filename)\n",
        "\n",
        "# Example usage\n",
        "mytext = input('Type a word or sentence: ')\n",
        "audio = generate_and_save_wav(mytext)\n",
        "audio\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zbOlUV0cMrBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Intonation contour (pitch)\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Function to extract and plot the pitch contour\n",
        "def plot_pitch_contour(audio_file_path):\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "    # Define the range for expected pitch (fundamental frequency)\n",
        "    fmin = librosa.note_to_hz('C2')  # Example minimum pitch\n",
        "    fmax = librosa.note_to_hz('C6')  # Example maximum pitch\n",
        "\n",
        "    # Extract the pitch contour using YIN algorithm\n",
        "    pitch, voiced_flag, voiced_probs = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=sr)\n",
        "\n",
        "    # Replace NaNs with zeros (unvoiced segments)\n",
        "    pitch[~np.isfinite(pitch)] = 0\n",
        "\n",
        "    # Plot the pitch contour\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    times = librosa.times_like(pitch, sr=sr)\n",
        "\n",
        "    # Plot only non-zero pitch values\n",
        "    for i in range(len(pitch)):\n",
        "        if pitch[i] > 0:\n",
        "            plt.plot(times[i], pitch[i], 'ro')  # Red dot for each non-zero pitch\n",
        "\n",
        "    plt.title('Pitch Contour')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Pitch (Hz)')\n",
        "    plt.ylim(0,350)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "print(f\"This is one possible intonation of: {mytext}\")\n",
        "plot_pitch_contour('/content/output.wav')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_K2jjA2kPMHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part II. Upload a file and draw visible pitch countour**"
      ],
      "metadata": {
        "id": "9NF3-46L7K6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Load your file\n",
        "from google.colab import files\n",
        "from IPython.display import Audio\n",
        "import os\n",
        "\n",
        "# Upload the WAV file\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))\n",
        "\n",
        "# Check if the uploaded file is a WAV file and rename it\n",
        "if filename.endswith('.wav'):\n",
        "    os.rename(filename, 'myspeech.wav')\n",
        "    print(\"Uploaded file has been renamed to 'myspeech.wav'. You can play it below:\")\n",
        "    display(Audio('myspeech.wav'))\n",
        "else:\n",
        "    print(\"Please upload a WAV audio file.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e5NxLa-O7r-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Intonation contour (pitch)\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Function to extract and plot the pitch contour\n",
        "def plot_pitch_contour(audio_file_path):\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "    # Define the range for expected pitch (fundamental frequency)\n",
        "    fmin = librosa.note_to_hz('C2')  # Example minimum pitch\n",
        "    fmax = librosa.note_to_hz('C7')  # Example maximum pitch\n",
        "\n",
        "    # Extract the pitch contour using YIN algorithm\n",
        "    pitch, voiced_flag, voiced_probs = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=sr)\n",
        "\n",
        "    # Replace NaNs with zeros (unvoiced segments)\n",
        "    pitch[~np.isfinite(pitch)] = 0\n",
        "\n",
        "    # Plot the pitch contour\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    times = librosa.times_like(pitch, sr=sr)\n",
        "\n",
        "    # Plot only non-zero pitch values\n",
        "    for i in range(len(pitch)):\n",
        "        if pitch[i] > 0:\n",
        "            plt.plot(times[i], pitch[i], 'ro')  # Red dot for each non-zero pitch\n",
        "\n",
        "    plt.title('Pitch Contour')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Pitch (Hz)')\n",
        "    plt.ylim(0,350)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "print(f\"This is the pitch contour of your speech file.\")\n",
        "plot_pitch_contour('/content/myspeech.wav')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k0dZjdjD70QH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}