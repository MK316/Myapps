{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN+7U22qyaW0+fdJ0IUvPhR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Myapps/blob/main/mrkim21apps/Oxford3Kaudio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G2duXkIbdpF"
      },
      "outputs": [],
      "source": [
        "!pip install gradio gtts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!apt-get install ffmpeg"
      ],
      "metadata": {
        "id": "KaHedhMZczG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "import pandas as pd\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "# Read the CSV data directly for demonstration purposes\n",
        "# Here you should load your actual data\n",
        "\n",
        "csv_file = \"/content/Oxford3K.csv\"\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "def generate_speech(x, y):\n",
        "    # Ensure x and y are integers\n",
        "    x, y = int(x), int(y)\n",
        "\n",
        "    # Create an empty audio segment for padding\n",
        "    combined_audio = AudioSegment.silent(duration=1000)  # Starting with 1 second of silence for padding\n",
        "\n",
        "    # Generate speech for each entry in the specified range\n",
        "    for index, row in df.iloc[x-1:y].iterrows():\n",
        "        sentence = f\"Number {row['SID']}. {row['WORD']} is a {row['POS']}.\"\n",
        "        tts = gTTS(text=sentence, lang='en')\n",
        "        mp3_fp = io.BytesIO()\n",
        "        tts.write_to_fp(mp3_fp)\n",
        "        mp3_fp.seek(0)\n",
        "        sentence_audio = AudioSegment.from_file(mp3_fp, format='mp3')\n",
        "        # Add the sentence audio and 2 seconds of silence\n",
        "        combined_audio += sentence_audio + AudioSegment.silent(duration=2000)\n",
        "\n",
        "    # Export the combined audio to a BytesIO object and return the bytes\n",
        "    mp3_io = io.BytesIO()\n",
        "    combined_audio.export(mp3_io, format='mp3')\n",
        "    mp3_io.seek(0)\n",
        "    return mp3_io.read()\n",
        "\n",
        "# Define the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_speech,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Start Sentence Number (x)\"),  # Assume the `default` parameter is removed if it causes an error\n",
        "        gr.Number(label=\"End Sentence Number (y)\")\n",
        "    ],\n",
        "    outputs=gr.Audio(label=\"Generated Speech\"),\n",
        "    title=\"Speech Generator\",\n",
        "    description=\"Generate speech from the CSV data. Specify the start and end sentence numbers.\"\n",
        ")\n",
        "\n",
        "\n",
        "# Launch the Gradio app with sharing enabled\n",
        "\n",
        "iface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "-g03n1Fwbp_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# By category (option)"
      ],
      "metadata": {
        "id": "dD80IAVUhpYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "import pandas as pd\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "\n",
        "# Load your CSV data into 'df'\n",
        "# df = pd.read_csv('path_to_your_csv.csv')\n",
        "\n",
        "def generate_speech_for_level(level):\n",
        "    # Find the range of SIDs for the selected level\n",
        "    level_df = df[df['LEVEL'] == level]\n",
        "    if not level_df.empty:\n",
        "        x = level_df['SID'].min()\n",
        "        y = level_df['SID'].max()\n",
        "        return generate_speech(x, y)\n",
        "    else:\n",
        "        return \"No data found for the selected level.\", 22050\n",
        "\n",
        "def generate_speech(x, y):\n",
        "    # Ensure x and y are integers\n",
        "    x = int(x)\n",
        "    y = int(y)\n",
        "\n",
        "    # Create an empty audio segment for padding\n",
        "    combined_audio = AudioSegment.silent(duration=1000)  # Starting with 1 second of silence for padding\n",
        "\n",
        "    # Generate speech for each entry in the specified range\n",
        "    for index, row in df.iloc[x-1:y].iterrows():\n",
        "        sentence = f\"Number {row['SID']}. {row['WORD']} is {row['POS']}.\"\n",
        "        tts = gTTS(text=sentence, lang='en')\n",
        "        mp3_fp = io.BytesIO()\n",
        "        tts.write_to_fp(mp3_fp)\n",
        "        mp3_fp.seek(0)\n",
        "        sentence_audio = AudioSegment.from_file(mp3_fp, format='mp3')\n",
        "        combined_audio += sentence_audio + AudioSegment.silent(duration=2000)\n",
        "\n",
        "    mp3_io = io.BytesIO()\n",
        "    combined_audio.export(mp3_io, format='mp3')\n",
        "    mp3_io.seek(0)\n",
        "    return mp3_io.read()\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        b2_button = gr.Button(\"B2 Level\")\n",
        "        c1_button = gr.Button(\"C1 Level\")\n",
        "    with gr.Row():\n",
        "        x_input = gr.Number(label=\"Start Sentence Number (x)\")\n",
        "        y_input = gr.Number(label=\"End Sentence Number (y)\")\n",
        "        generate_button = gr.Button(\"Generate Speech\")\n",
        "\n",
        "    audio_output = gr.Audio(label=\"Generated Speech\")\n",
        "\n",
        "    b2_button.click(fn=lambda: generate_speech_for_level(\"B2\"), inputs=[], outputs=audio_output)\n",
        "    c1_button.click(fn=lambda: generate_speech_for_level(\"C1\"), inputs=[], outputs=audio_output)\n",
        "    generate_button.click(fn=generate_speech, inputs=[x_input, y_input], outputs=audio_output)\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "oKyvlgWViQWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "import pandas as pd\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "\n",
        "# Assuming 'df' is your DataFrame loaded with the CSV data\n",
        "\n",
        "def update_sid_range_from_level(b2_checked, c1_checked):\n",
        "    levels = []\n",
        "    if b2_checked:\n",
        "        levels.append(\"B2\")\n",
        "    if c1_checked:\n",
        "        levels.append(\"C1\")\n",
        "\n",
        "    # Find the range of SIDs for the selected levels\n",
        "    if levels:\n",
        "        level_df = df[df['LEVEL'].isin(levels)]\n",
        "        x = level_df['SID'].min() if not level_df.empty else \"Not Available\"\n",
        "        y = level_df['SID'].max() if not level_df.empty else \"Not Available\"\n",
        "    else:\n",
        "        x, y = \"Select a level\", \"Select a level\"\n",
        "\n",
        "    return str(x), str(y)\n",
        "\n",
        "def generate_speech(x, y):\n",
        "    # No need to check if x and y are digits since they're already integers\n",
        "    x = int(x)  # This conversion is now redundant but kept for clarity\n",
        "    y = int(y)  # Same as above\n",
        "\n",
        "    combined_audio = AudioSegment.silent(duration=1000)  # Start with silence for padding\n",
        "\n",
        "    if x <= y:\n",
        "        for _, row in df.iloc[x-1:y].iterrows():\n",
        "            sentence = f\"Number {row['SID']}. {row['WORD']} is {row['POS']}.\"\n",
        "            tts = gTTS(text=sentence, lang='en')\n",
        "            mp3_fp = io.BytesIO()\n",
        "            tts.write_to_fp(mp3_fp)\n",
        "            mp3_fp.seek(0)\n",
        "            sentence_audio = AudioSegment.from_file(mp3_fp, format=\"mp3\")\n",
        "            combined_audio += sentence_audio + AudioSegment.silent(duration=2000)\n",
        "\n",
        "    mp3_io = io.BytesIO()\n",
        "    combined_audio.export(mp3_io, format=\"mp3\")\n",
        "    mp3_io.seek(0)\n",
        "    return mp3_io.getvalue()\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    b2_checkbox = gr.Checkbox(label=\"B2 Level\", value=False)\n",
        "    c1_checkbox = gr.Checkbox(label=\"C1 Level\", value=False)\n",
        "    x_output = gr.Textbox(label=\"Start SID (x)\", value=\"Select a level\", interactive=False)\n",
        "    y_output = gr.Textbox(label=\"End SID (y)\", value=\"Select a level\", interactive=False)\n",
        "    x_input = gr.Number(label=\"Enter Start SID (x)\", value=1)\n",
        "    y_input = gr.Number(label=\"Enter End SID (y)\", value=2)\n",
        "    generate_button = gr.Button(\"Generate Speech\")\n",
        "    audio_output = gr.Audio(label=\"Generated Speech\")\n",
        "\n",
        "    def update_checkboxes(b2, c1):\n",
        "        return update_sid_range_from_level(b2, c1)\n",
        "\n",
        "    # Attach the change event to each checkbox, calling the same function\n",
        "    b2_checkbox.change(fn=update_checkboxes, inputs=[b2_checkbox, c1_checkbox], outputs=[x_output, y_output])\n",
        "    c1_checkbox.change(fn=update_checkboxes, inputs=[b2_checkbox, c1_checkbox], outputs=[x_output, y_output])\n",
        "\n",
        "    generate_button.click(fn=generate_speech, inputs=[x_input, y_input], outputs=audio_output)\n",
        "\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "SAE8uiksjt44"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}