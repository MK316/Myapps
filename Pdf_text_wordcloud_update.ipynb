{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOx6XA8NE3UbcOh0SJiLtMX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Myapps/blob/main/Pdf_text_wordcloud_update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "VbUBBgFlLV8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud"
      ],
      "metadata": {
        "id": "fFLCgmtlOu3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdP9tEagK7i2"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import requests\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Downloading NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def extract_text_from_pdf(url):\n",
        "    response = requests.get(url)\n",
        "    with open('temp.pdf', 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    with open('temp.pdf', 'rb') as file:\n",
        "        reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def process_text(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [lemmatizer.lemmatize(word.lower()) for word in words if word.isalpha() and word.lower() not in stop_words and len(word) >= 3]\n",
        "    return Counter(filtered_words)\n",
        "\n",
        "def display_top_words(url, top_n=10):\n",
        "    text = extract_text_from_pdf(url)\n",
        "    word_freq = process_text(text)\n",
        "    return word_freq.most_common(top_n)\n",
        "\n",
        "# Example usage\n",
        "github_pdf_url = \"https://raw.github.com/MK316/TExams/main/data/2023A.pdf\"  # Replace with your GitHub PDF URL\n",
        "top_words = display_top_words(github_pdf_url, 10)  # Display top 10 words\n",
        "print(top_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_word_cloud(text):\n",
        "    # Generate word cloud with all words horizontal\n",
        "    wordcloud = WordCloud(width=800, height=800,\n",
        "                          background_color='white',\n",
        "                          prefer_horizontal=1.0,  # Ensures horizontal layout\n",
        "                          min_font_size=10).generate(text)\n",
        "\n",
        "    # Plot the WordCloud image\n",
        "    plt.figure(figsize=(8, 8), facecolor=None)\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout(pad=0)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def generate_word_cloud_text(url):\n",
        "    raw_text = extract_text_from_pdf(url)\n",
        "    processed_words = process_text(raw_text)\n",
        "\n",
        "    # Combine unique words for word cloud\n",
        "    cloud_text = ' '.join(processed_words.keys())\n",
        "    create_word_cloud(cloud_text)\n",
        "\n",
        "    return processed_words\n",
        "\n",
        "\n",
        "# Example usage\n",
        "github_pdf_url = \"https://raw.github.com/MK316/TExams/main/data/2023A.pdf\"  # Replace with your GitHub PDF URL\n",
        "generate_word_cloud_text(github_pdf_url)\n",
        "\n",
        "processed_words = generate_word_cloud_text(github_pdf_url)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLFyN2oFO6W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_processed_words = update_and_regenerate_word_cloud(processed_words)"
      ],
      "metadata": {
        "id": "zyBgE5z0VSTI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}