{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNiXWaLt9cHpOuPsKX1YoxI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Myapps/blob/main/TCEapps/stress_intonation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“—**Chapter 7 Stress and intonation (F23)**\n",
        "\n",
        "**Goal:** Learn stress placement with sound - 160 words listed in Chapter 7\n",
        "+ Wordlist (csv file) [Wordlist 160](https://raw.githubusercontent.com/MK316/Myapps/main/data/stress160.csv)"
      ],
      "metadata": {
        "id": "zhqKIwu7w8Kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part I: Play sound to learn stress**"
      ],
      "metadata": {
        "id": "y6vJiTHDu5RH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting: install packages"
      ],
      "metadata": {
        "id": "BhQ9PyDI74jm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-mB6lyMyFr5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ðŸ“Œ Run this code before you start\n",
        "%%capture\n",
        "!pip install gradio pandas gtts requests librosa matplotlib pydub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instruction:** run the code below and you'll get a live link (or you can practice with the app here.\n",
        "\n",
        "+ ID: 1~160\n",
        "+ Words: listed words\n",
        "\n",
        "Note: You can type either the ID number or the word to play the sound"
      ],
      "metadata": {
        "id": "rXvotg6N7gMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ðŸŒ€ Gradio link\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import requests\n",
        "from gtts import gTTS\n",
        "from io import BytesIO\n",
        "\n",
        "# URL of the raw CSV file on GitHub\n",
        "csv_url = 'https://raw.githubusercontent.com/MK316/Myapps/main/data/stress160.csv'\n",
        "\n",
        "# Use requests to get the CSV file content from GitHub\n",
        "response = requests.get(csv_url)\n",
        "assert response.status_code == 200, 'Failed to download CSV file'\n",
        "\n",
        "# Load the CSV content into a DataFrame\n",
        "df = pd.read_csv(BytesIO(response.content))\n",
        "\n",
        "def generate_audio_by_id(word_id):\n",
        "    word = df.loc[df['ID'] == word_id, 'Words'].values[0]\n",
        "    return text_to_speech(word)\n",
        "\n",
        "def generate_audio_by_word(word):\n",
        "    if word in df['Words'].values:\n",
        "        audio_path = text_to_speech(word)\n",
        "        return audio_path, \"\"  # Return the path and an empty status message\n",
        "    else:\n",
        "        return None, \"Word not found in the list.\"  # Return None and a status message\n",
        "\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "def text_to_speech(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as f:\n",
        "        tts.save(f.name)\n",
        "        return f.name  # Return the path to the saved file\n",
        "\n",
        "\n",
        "def search_and_generate_audio(search_by, query):\n",
        "    if search_by == 'ID':\n",
        "        try:\n",
        "            query = int(query)  # Convert ID to integer\n",
        "            audio_path = generate_audio_by_id(query)\n",
        "            return audio_path, \"\"\n",
        "        except ValueError:\n",
        "            return None, \"ID must be an integer.\"\n",
        "    elif search_by == 'Words':\n",
        "        audio_path, status = generate_audio_by_word(query)\n",
        "        return audio_path, status\n",
        "    else:\n",
        "        return None, \"Please select a valid search option.\"\n",
        "\n",
        "\n",
        "# Define the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=search_and_generate_audio,\n",
        "    inputs=[\n",
        "        gr.Radio(['ID', 'Words'], label=\"Search by:\"),\n",
        "        gr.Textbox(label=\"Enter ID or Word:\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Audio(label=\"Audio of the word\"),\n",
        "        gr.Textbox(label=\"Status\")\n",
        "    ],\n",
        "    title=\"Word Audio Generator\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E00LZprLu-SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate speech file to download"
      ],
      "metadata": {
        "id": "czkZLkR_8jTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ðŸŒ€ Generate speech from x to y (x, y = ID numbers)\n",
        "import pandas as pd\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio\n",
        "import os\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MK316/Myapps/main/data/stress160.csv\"\n",
        "\n",
        "# Function to generate speech with pauses\n",
        "def generate_speech_with_pause(github_url, from_id, to_id):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(github_url)\n",
        "\n",
        "    # Filter rows based on the ID range\n",
        "    filtered_df = df[(df['ID'] >= from_id) & (df['ID'] <= to_id)]\n",
        "\n",
        "    # Create a silent audio segment for a 2-second pause\n",
        "    pause = AudioSegment.silent(duration=1000)  # 2000 milliseconds = 2 seconds\n",
        "\n",
        "    # Initialize an empty audio segment\n",
        "    combined = AudioSegment.empty()\n",
        "\n",
        "    # Loop through each word, generate speech, and add a pause\n",
        "    for word in filtered_df['Words']:\n",
        "        tts = gTTS(word)\n",
        "        tts.save(\"temp.mp3\")\n",
        "        word_audio = AudioSegment.from_mp3(\"temp.mp3\")\n",
        "        combined += word_audio + pause\n",
        "        os.remove(\"temp.mp3\")  # Clean up the temporary file\n",
        "\n",
        "    # Save the final combined audio\n",
        "    combined.export(\"output.mp3\", format=\"mp3\")\n",
        "\n",
        "    # Play the audio\n",
        "    return Audio(\"output.mp3\")\n",
        "\n",
        "# Example usage\n",
        "github_url = url  # Replace with your GitHub URL\n",
        "from_id = int(input('Start ID: '))  # User input for start ID\n",
        "to_id = int(input('End ID: '))      # User input for end ID\n",
        "audio = generate_speech_with_pause(github_url, from_id, to_id)\n",
        "audio\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ncyR2545-pBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part II: Reading a sentence to learn basic intonation**"
      ],
      "metadata": {
        "id": "VfUQ8V-hxQ-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ðŸŒ€ Sentence reading\n",
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# Define the function to convert text to speech and save it to a temporary file\n",
        "def text_to_speech(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    # Create a temporary file to save the audio\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as f:\n",
        "        tts.save(f.name)\n",
        "        # Return the path to the saved audio file\n",
        "        return f.name\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=text_to_speech,\n",
        "    inputs=gr.Textbox(placeholder=\"Type a sentence here...\"),\n",
        "    outputs=gr.Audio(),\n",
        "    title=\"Text to Speech\",\n",
        "    description=\"Enter a sentence to convert it to speech.\"\n",
        ")\n",
        "\n",
        "# Launch the interface and create a shareable link\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "222-Be9oxTE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part III. Visible pitch contour (intonation)**\n"
      ],
      "metadata": {
        "id": "vFtpgBBs_c63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown [1] Generate speech audio file: you can type a word or sentence\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "from IPython.display import Audio  # Import the Audio class for playing audio\n",
        "\n",
        "# Function to generate and save a WAV file\n",
        "def generate_and_save_wav(word, filename='output.wav'):\n",
        "    # Generate speech using gTTS\n",
        "    tts = gTTS(text=word, lang='en')\n",
        "\n",
        "    # Save as MP3 in memory\n",
        "    mp3_fp = BytesIO()\n",
        "    tts.write_to_fp(mp3_fp)\n",
        "    mp3_fp.seek(0)\n",
        "\n",
        "    # Convert MP3 to WAV\n",
        "    sound = AudioSegment.from_file(mp3_fp, format=\"mp3\")\n",
        "    sound.export(filename, format=\"wav\")\n",
        "\n",
        "    # Play the audio\n",
        "    return Audio(filename)\n",
        "\n",
        "# Example usage\n",
        "mytext = input('Type a word or sentence: ')\n",
        "audio = generate_and_save_wav(mytext)\n",
        "audio\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zbOlUV0cMrBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Intonation contour (pitch)\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Function to extract and plot the pitch contour\n",
        "def plot_pitch_contour(audio_file_path):\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "    # Define the range for expected pitch (fundamental frequency)\n",
        "    fmin = librosa.note_to_hz('C2')  # Example minimum pitch\n",
        "    fmax = librosa.note_to_hz('C6')  # Example maximum pitch\n",
        "\n",
        "    # Extract the pitch contour using YIN algorithm\n",
        "    pitch, voiced_flag, voiced_probs = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=sr)\n",
        "\n",
        "    # Replace NaNs with zeros (unvoiced segments)\n",
        "    pitch[~np.isfinite(pitch)] = 0\n",
        "\n",
        "    # Plot the pitch contour\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    times = librosa.times_like(pitch, sr=sr)\n",
        "\n",
        "    # Plot only non-zero pitch values\n",
        "    for i in range(len(pitch)):\n",
        "        if pitch[i] > 0:\n",
        "            plt.plot(times[i], pitch[i], 'ro')  # Red dot for each non-zero pitch\n",
        "\n",
        "    plt.title('Pitch Contour')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Pitch (Hz)')\n",
        "    plt.ylim(0,350)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "print(f\"This is one possible intonation of: {mytext}\")\n",
        "plot_pitch_contour('/content/output.wav')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_K2jjA2kPMHN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}