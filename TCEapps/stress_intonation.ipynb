{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMYALpStSlw2Pndwgj608OR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Myapps/blob/main/TCEapps/stress_intonation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“—**Chapter 7 Stress and intonation (F23)**\n",
        "\n",
        "**Goal:** Learn stress placement with sound - 160 words listed in Chapter 7\n",
        "+ Wordlist (csv file) [Wordlist 160](https://raw.githubusercontent.com/MK316/Myapps/main/data/stress160.csv)"
      ],
      "metadata": {
        "id": "zhqKIwu7w8Kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part I: Play sound to learn stress**"
      ],
      "metadata": {
        "id": "y6vJiTHDu5RH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting: install packages"
      ],
      "metadata": {
        "id": "BhQ9PyDI74jm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-mB6lyMyFr5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ðŸ“Œ Run this code before you start\n",
        "%%capture\n",
        "!pip install pyqrcode gradio pandas gtts requests librosa matplotlib pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **[optional]** QR code to generate. You'll be prompted to nter link address\n",
        "\n",
        "\n",
        "import pyqrcode\n",
        "from pyqrcode import QRCode\n",
        "\n",
        "#@markdown Enter the link, save it as a file, and display\n",
        "s = input(\"Paste the link: \")\n",
        "\n",
        "# Generate QR code\n",
        "url = pyqrcode.create(s)\n",
        "\n",
        "# Create and save the png file naming \"myqr.png\"\n",
        "url.svg(\"myqrcode.svg\", scale=10)\n",
        "\n",
        "from IPython.display import SVG, display\n",
        "def show_svg(file):\n",
        "    display(SVG(file))\n",
        "\n",
        "show_svg(\"myqrcode.svg\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8pHeYATwLW4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instruction:** run the code below and you'll get a live link (or you can practice with the app here.\n",
        "\n",
        "+ ID: 1~160\n",
        "+ Words: listed words\n",
        "\n",
        "Note: You can type either the ID number or the word to play the sound. Words that are not in the list also can be generated."
      ],
      "metadata": {
        "id": "rXvotg6N7gMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ðŸŒ€ Gradio link\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import requests\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "# URL of the raw CSV file on GitHub\n",
        "csv_url = 'https://raw.githubusercontent.com/MK316/Myapps/main/data/stress160.csv'\n",
        "\n",
        "# Use requests to get the CSV file content from GitHub\n",
        "response = requests.get(csv_url)\n",
        "assert response.status_code == 200, 'Failed to download CSV file'\n",
        "\n",
        "# Load the CSV content into a DataFrame\n",
        "df = pd.read_csv(BytesIO(response.content))\n",
        "\n",
        "def generate_audio_by_id(word_id):\n",
        "    word = df.loc[df['ID'] == word_id, 'Words'].values[0]\n",
        "    return text_to_speech(word)\n",
        "\n",
        "def generate_audio_by_word(word):\n",
        "    # Always generate speech regardless of the word being in the list or not\n",
        "    return text_to_speech(word), \"\"\n",
        "\n",
        "def text_to_speech(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as f:\n",
        "        tts.save(f.name)\n",
        "        # Return the path to the saved file\n",
        "        return f.name\n",
        "\n",
        "def search_and_generate_audio(search_by, query):\n",
        "    if search_by == 'ID':\n",
        "        try:\n",
        "            query = int(query)  # Convert ID to integer\n",
        "            audio_path = generate_audio_by_id(query)\n",
        "            return audio_path, \"\"\n",
        "        except ValueError:\n",
        "            return None, \"ID must be an integer.\"\n",
        "    elif search_by == 'Words':\n",
        "        audio_path, status = generate_audio_by_word(query)\n",
        "        return audio_path, status\n",
        "    else:\n",
        "        return None, \"Please select a valid search option.\"\n",
        "\n",
        "# Define the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=search_and_generate_audio,\n",
        "    inputs=[\n",
        "        gr.Radio(['ID', 'Words'], label=\"Search by:\"),\n",
        "        gr.Textbox(label=\"Enter ID or Word:\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Audio(label=\"Audio of the word\"),\n",
        "        gr.Textbox(label=\"Status\")\n",
        "    ],\n",
        "    title=\"Word Audio Generator\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EFMRkGSoK32K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate speech file to download"
      ],
      "metadata": {
        "id": "czkZLkR_8jTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Save audio file from x to y (you can download the file from the panel on the left)\n",
        "import pandas as pd\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio\n",
        "import os\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MK316/Myapps/main/data/stress160.csv\"\n",
        "\n",
        "def generate_speech_with_pause(github_url, from_id, to_id):\n",
        "    df = pd.read_csv(github_url)\n",
        "    filtered_df = df[(df['ID'] >= from_id) & (df['ID'] <= to_id)]\n",
        "\n",
        "    pause = AudioSegment.silent(duration=1000)  # 1000 milliseconds = 1 second\n",
        "    combined = AudioSegment.empty()\n",
        "\n",
        "    for word in filtered_df['Words']:\n",
        "        tts = gTTS(word)\n",
        "        tts.save(\"temp.mp3\")\n",
        "        word_audio = AudioSegment.from_mp3(\"temp.mp3\")\n",
        "        combined += word_audio + pause\n",
        "        os.remove(\"temp.mp3\")  # Clean up the temporary file\n",
        "\n",
        "    # Generate the filename based on the ID range\n",
        "    filename = f\"{from_id}_{to_id}.mp3\"\n",
        "    combined.export(filename, format=\"mp3\")\n",
        "\n",
        "    return Audio(filename)\n",
        "\n",
        "# Example usage\n",
        "github_url = url\n",
        "from_id = int(input('Start ID: '))\n",
        "to_id = int(input('End ID: '))\n",
        "audio = generate_speech_with_pause(github_url, from_id, to_id)\n",
        "audio\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8bs5Z6pWOaEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part II: Reading a sentence to learn basic intonation**"
      ],
      "metadata": {
        "id": "VfUQ8V-hxQ-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ðŸŒ€ Sentence reading\n",
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# Define the function to convert text to speech and save it to a temporary file\n",
        "def text_to_speech(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    # Create a temporary file to save the audio\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as f:\n",
        "        tts.save(f.name)\n",
        "        # Return the path to the saved audio file\n",
        "        return f.name\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=text_to_speech,\n",
        "    inputs=gr.Textbox(placeholder=\"Type a sentence here...\"),\n",
        "    outputs=gr.Audio(),\n",
        "    title=\"Text to Speech\",\n",
        "    description=\"Enter a sentence to convert it to speech.\"\n",
        ")\n",
        "\n",
        "# Launch the interface and create a shareable link\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "222-Be9oxTE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part III. Visible pitch contour (intonation)**\n"
      ],
      "metadata": {
        "id": "vFtpgBBs_c63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown [1] Generate speech audio file: you can type a word or sentence\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "from IPython.display import Audio  # Import the Audio class for playing audio\n",
        "\n",
        "# Function to generate and save a WAV file\n",
        "def generate_and_save_wav(word, filename='output.wav'):\n",
        "    # Generate speech using gTTS\n",
        "    tts = gTTS(text=word, lang='en')\n",
        "\n",
        "    # Save as MP3 in memory\n",
        "    mp3_fp = BytesIO()\n",
        "    tts.write_to_fp(mp3_fp)\n",
        "    mp3_fp.seek(0)\n",
        "\n",
        "    # Convert MP3 to WAV\n",
        "    sound = AudioSegment.from_file(mp3_fp, format=\"mp3\")\n",
        "    sound.export(filename, format=\"wav\")\n",
        "\n",
        "    # Play the audio\n",
        "    return Audio(filename)\n",
        "\n",
        "# Example usage\n",
        "mytext = input('Type a word or sentence: ')\n",
        "audio = generate_and_save_wav(mytext)\n",
        "audio\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zbOlUV0cMrBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Intonation contour (pitch)\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Function to extract and plot the pitch contour\n",
        "def plot_pitch_contour(audio_file_path):\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "    # Define the range for expected pitch (fundamental frequency)\n",
        "    fmin = librosa.note_to_hz('C2')  # Example minimum pitch\n",
        "    fmax = librosa.note_to_hz('C6')  # Example maximum pitch\n",
        "\n",
        "    # Extract the pitch contour using YIN algorithm\n",
        "    pitch, voiced_flag, voiced_probs = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=sr)\n",
        "\n",
        "    # Replace NaNs with zeros (unvoiced segments)\n",
        "    pitch[~np.isfinite(pitch)] = 0\n",
        "\n",
        "    # Plot the pitch contour\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    librosa.display.waveshow(y, sr=sr)\n",
        "    times = librosa.times_like(pitch, sr=sr)\n",
        "\n",
        "    # Plot only non-zero pitch values\n",
        "    for i in range(len(pitch)):\n",
        "        if pitch[i] > 0:\n",
        "            plt.plot(times[i], pitch[i], 'ro')  # Red dot for each non-zero pitch\n",
        "\n",
        "    plt.title('Pitch Contour')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Pitch (Hz)')\n",
        "    plt.ylim(0,350)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "print(f\"This is one possible intonation of: {mytext}\")\n",
        "plot_pitch_contour('/content/output.wav')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_K2jjA2kPMHN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}